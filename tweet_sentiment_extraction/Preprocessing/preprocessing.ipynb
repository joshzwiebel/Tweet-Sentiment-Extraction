{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"b7386427-621a-413c-a8a8-e80c0ebffd3f"},"source":"import pandas as pd \r\nimport numpy as np\r\nimport re\r\nimport difflib as diff\r\nimport spellchecker","execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'indexer'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-dfff7f1c8731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdifflib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspellchecker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/spellchecker/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m  \u001b[0mspellchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpellchecker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgetInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/spellchecker/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionaryIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_detect_lang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'indexer'"]}]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{"tags":[],"cell_id":"559925d4-1f7b-4819-a172-559f33c8f3a2"}},{"cell_type":"markdown","source":"Preprocessing is a vital part of the data cleaning process and can lead to huge gains in performance","metadata":{"tags":[],"cell_id":"cf315764-8329-4311-9cd5-8bdc20eb12e5"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"f37c8263-6d5c-41ac-a4a8-ea399cc77ae3"},"source":"df = pd.read_csv(\"../Data/train.csv\")\r\ndf.head()","outputs":[{"output_type":"execute_result","execution_count":41,"data":{"application/vnd.deepnote.dataframe+json":{"variableDetails":{"dataframe":{"0":{"textID":"cb774db0d1","text":" I`d have responded, if I were going","selected_text":"I`d have responded, if I were going","sentiment":"neutral"},"1":{"textID":"549e992a42","text":" Sooo SAD I will miss you here in San Diego!!!","selected_text":"Sooo SAD","sentiment":"negative"},"2":{"textID":"088c60f138","text":"my boss is bullying me...","selected_text":"bullying me","sentiment":"negative"},"3":{"textID":"9642c003ef","text":" what interview! leave me alone","selected_text":"leave me alone","sentiment":"negative"},"4":{"textID":"358bd9e861","text":" Sons of ****, why couldn`t they put them on the releases we already bought","selected_text":"Sons of ****,","sentiment":"negative"}},"columns":[{"name":"textID","stats":{"count":5,"unique":5,"top":"358bd9e861","freq":1,"nan_count":0}},{"name":"text","stats":{"count":5,"unique":5,"top":"my boss is bullying me...","freq":1,"nan_count":0}},{"name":"selected_text","stats":{"count":5,"unique":5,"top":"I`d have responded, if I were going","freq":1,"nan_count":0}},{"name":"sentiment","stats":{"count":5,"unique":2,"top":"negative","freq":4,"nan_count":0}}],"frequencyInfo":[{"frequencyData":[{"name":"cb774db0d1","frequency":0.2},{"name":"549e992a42","frequency":0.2},{"name":"3 others","frequency":0.6}],"type":"freq"},{"frequencyData":[{"name":" I`d have responded, if I were going","frequency":0.2},{"name":" Sooo SAD I will miss you here in San Diego!!!","frequency":0.2},{"name":"3 others","frequency":0.6}],"type":"freq"},{"frequencyData":[{"name":"I`d have responded, if I were going","frequency":0.2},{"name":"Sooo SAD","frequency":0.2},{"name":"3 others","frequency":0.6}],"type":"freq"},{"frequencyData":[{"name":"negative","frequency":0.8},{"name":"neutral","frequency":0.2}],"type":"freq"}]},"numElements":5,"numColumns":4},"text/plain":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment  \n0  I`d have responded, if I were going   neutral  \n1                             Sooo SAD  negative  \n2                          bullying me  negative  \n3                       leave me alone  negative  \n4                        Sons of ****,  negative  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We will have to do a few things in order to prepare this data for training\r\n\r\n1. Clean up the text features\r\n2. Turn selected text into target indices for easier prediction\r\n\r\nIt would be possible to train a model using selected text as a target using an encoder decoder model but for ease of programming and prediction we decided it would be a better idea to predict indices and then use the indices to slice the original text","metadata":{"tags":[],"cell_id":"e3af1e97-9e1c-4ace-8e5c-51767816e0a9"}},{"cell_type":"markdown","source":"To do that we will need to find the starting and ending indices for the selected text within the true text","metadata":{"tags":[],"cell_id":"0109cba3-d274-481b-86d5-a27cbbcd1c7e"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"ffd5227e-274d-4ecd-b311-5d834245ee32"},"source":"df[\"text_split\"]=df.text.apply(lambda row: str(row).split())\r\ndf[\"text_split\"].head()","outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"0          [I`d, have, responded,, if, I, were, going]\n1    [Sooo, SAD, I, will, miss, you, here, in, San,...\n2                      [my, boss, is, bullying, me...]\n3                 [what, interview!, leave, me, alone]\n4    [Sons, of, ****,, why, couldn`t, they, put, th...\nName: text_split, dtype: object"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"97ab6f0f-1519-4be5-b606-59166ba34331"},"source":"df[\"selected_text_split\"]=df.selected_text.apply(lambda row: str(row).split())\r\ndf[\"selected_text_split\"]","outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"0              [I`d, have, responded,, if, I, were, going]\n1                                              [Sooo, SAD]\n2                                           [bullying, me]\n3                                       [leave, me, alone]\n4                                        [Sons, of, ****,]\n                               ...                        \n27476                                            [d, lost]\n27477                                    [,, don`t, force]\n27478                     [Yay, good, for, both, of, you.]\n27479                     [But, it, was, worth, it, ****.]\n27480    [All, this, flirting, going, on, -, The, ATG, ...\nName: selected_text_split, Length: 27481, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"Both text and selected text have been split on a word level now we need to match indices. The following code will find the indice of the selected text within the real text. These will become the target feature","metadata":{"tags":[],"cell_id":"c784acb7-1d1c-4f6c-b699-a914b8b96c0d"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e2798f69-3c50-40b4-b2da-297be40a65f8"},"source":"def index_finder(text,selected):\r\n    return text.index(selected[0])\r\ndf[\"initial_indice\"] = df.apply(lambda x: index_finder(x.text_split,x.selected_text_split),axis=1)\r\ndf[\"initial_indice\"]","outputs":[{"output_type":"error","ename":"ValueError","evalue":"(\"'onna' is not in list\", 'occurred at index 18')","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-c21e4b28ca6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_indice\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_text_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_indice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6904\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6905\u001b[0m         )\n\u001b[0;32m-> 6906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/venv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-c21e4b28ca6d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_indice\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_text_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_indice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-44-c21e4b28ca6d>\u001b[0m in \u001b[0;36mindex_finder\u001b[0;34m(text, selected)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindex_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_indice\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_text_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_indice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: (\"'onna' is not in list\", 'occurred at index 18')"]}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a77b0528-0dea-4282-bea7-6c2613f79e77"},"source":"df.iloc[18]","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"The above was an unintended result from the data. Whoever inputted the data meant to input \"gonna\" but actually input \"onna\". We will manually fix this case and hope there arent too many more mistakes","metadata":{"tags":[],"cell_id":"54fcbb18-7a63-4646-b462-219f7093d052"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a9fae370-7912-46da-bc41-3946830f6bbc"},"source":"df.selected_text_split[18] = [\"gonna\"]\r\ndf.selected_text_split.iloc[18]","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"Now lets try again","metadata":{"tags":[],"cell_id":"01e0b964-531b-4e3f-8c16-471e0a2fa7d4"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"337a4edf-f006-4f7c-bec1-f4ad8de07ce4"},"source":"def index_finder(text,selected):\r\n    return text.index(selected[0])\r\ndf[\"initial_indice\"] = df.apply(lambda x: index_finder(x.text_split,x.selected_text_split),axis=1)\r\ndf[\"initial_indice\"]","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"it happened again. It is worth testing how many times this error happens in order to gauge what approach must be taken","metadata":{"tags":[],"cell_id":"3e5d3e9b-3983-40a5-aa37-bd5230849284"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"3a254e24-61a1-4844-bd05-46c1c48f55c9"},"source":"errors = 0\r\ndef index_finder(text,selected):\r\n    global errors\r\n    try:\r\n        testing = text.index(selected[0])\r\n    except:\r\n        errors+=1\r\n\r\n\r\ndf[\"initial_indice\"] = df.apply(lambda x: index_finder(x.text_split,x.selected_text_split),axis=1)\r\nerrors","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"There are far too many to fix by hand. 1821 Is a very unreasonable number for 2 people to sit down and fix. We will turn to a more elegant solution. Difflib is a library that will find the most similar word and for our purposes it will be good enough","metadata":{"tags":[],"cell_id":"f94ed6c2-f06c-4bee-8d19-eba928324bea"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"4def779f-6c22-4e38-aac5-15e780403e25"},"source":"def index_finder(text,selected):\r\n    return text.index(diff.get_close_matches(selected[0],text)[0])\r\ndf[\"initial_indice\"] = df.apply(lambda x: index_finder(x.text_split,x.selected_text_split),axis=1)","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e943a6cb-38b4-4f32-bd17-e1d1da8aec09"},"source":"df.iloc[27]","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"Thsi was also unexpected. The selected text data starts with a period. It starts with the 3rd period in a grouping of 3. In this case we will have to do a much better job of cleaning the data. The next step to try and fix this problem would be to use regex to remove the punctuation","metadata":{"tags":[],"cell_id":"e7b559c8-c541-4077-a0a4-e1e9676b1798"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"8f73bdc9-3523-4acc-8d39-67764aee7130"},"source":"def clean(row):\r\n    row = row.replace('.', ' ')\r\n    row = row.replace(',', '')\r\n    row = row.replace(\"'\", \"\")\r\n    row = re.sub(\"\\d+\", \"<NUM>\", row)\r\n    row = re.sub(\"\\*+\", \"<CURSE>\", row)\r\n    row = re.sub(\"^@.*\", \"<USER>\", row)\r\n    row = re.sub(\"^#.*\", \"<HASH>\", row)\r\n    row = re.sub(\"^((https|http|ftp|file)?:\\/\\/).*\", \"<LINK>\", row)\r\n    row = re.sub(\"[0-9]+:[0-9]+(am|AM|pm|PM)?\", \"<DATE>\", row)\r\n    row = row.lower().strip()\r\n    return row.split()\r\ndf[\"text_split\"] = df.text.apply(lambda row: clean(str(row)))\r\ndf[\"selected_text_split\"] = df.selected_text.apply(lambda row: clean(str(row)))\r\ndf[\"text_split\"]\r\n\r\n\r\n","execution_count":0,"outputs":[]},{"cell_type":"markdown","source":"The below function will now check the tweets for any common mispellings and change them. This operation can take some time","metadata":{"tags":[],"cell_id":"cee96cfb-9c1a-43d2-a9b0-032e188988dd"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"bf71f73d-a0b9-4c61-a255-48cf34a30913"},"source":"spell = spellchecker.SpellChecker()\r\n\r\ndef check_spelling(row):\r\n    mispelled = spell.unknown(row)\r\n    for word in mispelled:\r\n        if word not in [\"<curse>\", \"<num>\", \"<user>\", \"<hash>\", '<link>', '<date>']:\r\n            row[row.index(word)] = spell.correction(word)\r\n    return row \r\ndf[\"text_split\"] = df.text_split.apply(lambda x: check_spelling(x))\r\ndf[\"selected_text_split\"] = df.selected_text_split.apply(lambda x: check_spelling(x))\r\n\r\ndf.text_split.head()","execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c5b682d3-f00f-4ac2-8449-8dfa7f484957"},"source":"df.selected_text_split.head()","outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"0    ['id', 'have', 'responded', 'if', 'i', 'were',...\n1                                      ['soon', 'sad']\n2                                   ['bullying', 'me']\n3                             ['leave', 'me', 'alone']\n4                            ['sons', 'of', '<curse>']\nName: selected_text_split, dtype: object"},"metadata":{}}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"fd54b325-e235-4e53-ba75-839d87b4d311"},"source":"df.selected_text_split[2][1]","outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"\"'\""},"metadata":{}}]},{"cell_type":"markdown","source":"And we can check out our new text data","metadata":{"tags":[],"cell_id":"f63445eb-5742-4672-9dec-9d13f27518bb"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"a7015697-0fd1-47ed-b70d-0afba86b4b3e"},"source":"df.to_csv(\"preprocessed_train.csv\")","execution_count":0,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_execution_queue":[]}}
